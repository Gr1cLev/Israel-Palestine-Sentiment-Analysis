{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25543652",
   "metadata": {},
   "source": [
    "# 01 — Preprocessing\n",
    "\n",
    "Tujuan:\n",
    "- Bersihkan & normalisasi teks:\n",
    "  **cleaning → lower → social/slang normalize → token → stopword → stemming**.\n",
    "- Keluaran:\n",
    "  - `reddit_opinion_PSE_ISR_2024_window_clean.csv`\n",
    "  - `reddit_opinion_PSE_ISR_2025_window_clean.csv`\n",
    "\n",
    "Catatan:\n",
    "- Pipeline identik antar-tahun (konsistensi train/test).\n",
    "- Tetap streaming (`chunksize`) untuk hemat RAM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b9c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ Imports ready\n",
      "CPU times: total: 2.5 s\n",
      "Wall time: 8.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%pip install -q ftfy ekphrasis emoji scikit-learn\n",
    "\n",
    "import os, re, hashlib, warnings\n",
    "import pandas as pd\n",
    "from ftfy import fix_text\n",
    "\n",
    "# NLTK komponen yg tanpa korpus eksternal\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from emoji import demojize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"✅ Imports ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fed1b5",
   "metadata": {},
   "source": [
    "## Konfigurasi file window & stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56456ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Config ready\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 19.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "IN_2024 = \"reddit_opinion_PSE_ISR_2024_window.csv\"\n",
    "IN_2025 = \"reddit_opinion_PSE_ISR_2025_window.csv\"\n",
    "\n",
    "OUT_2024 = \"reddit_opinion_PSE_ISR_2024_window_clean.csv\"\n",
    "OUT_2025 = \"reddit_opinion_PSE_ISR_2025_window_clean.csv\"\n",
    "\n",
    "CHUNKSIZE    = 500_000\n",
    "PREVIEW_ROWS = 5\n",
    "KEEP_COLS    = [\"comment_id\",\"created_time\",\"self_text\",\"score\",\"subreddit\"]\n",
    "\n",
    "# Stopwords (NLTK jika ada; fallback sklearn)\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "    STOPWORDS = set(stopwords.words(\"english\"))\n",
    "except Exception:\n",
    "    from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "    STOPWORDS = set(ENGLISH_STOP_WORDS)\n",
    "STOPWORDS |= {\"im\",\"u\",\"ur\",\"btw\",\"lol\",\"thx\"}\n",
    "\n",
    "STEMMER = PorterStemmer()\n",
    "TOK     = ToktokTokenizer()\n",
    "\n",
    "print(\"✅ Config ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e74824",
   "metadata": {},
   "source": [
    "## (Opsional) Lexicon slang & emoji + build `text_processor`\n",
    "\n",
    "- Jika tidak punya CSV kamus: pipeline jalan pakai fallback mini.\n",
    "- `text_processor` (ekphrasis) untuk normalisasi sosial: url/email/hashtag/elongated, dst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53ae8de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Optional) Not found: english_slang.csv\n",
      "(Optional) Not found: indonesian_slang.csv\n",
      "(Optional) Not found: emoji_map.csv\n",
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "✅ text_processor ready | slang entries: 21\n",
      "CPU times: total: 6.17 s\n",
      "Wall time: 6.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_lexicon_csv(path, key_col, val_col):\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        df = df[[key_col, val_col]].dropna()\n",
    "        df[key_col] = df[key_col].astype(str).str.strip().str.lower()\n",
    "        df[val_col] = df[val_col].astype(str).str.strip().str.lower()\n",
    "        print(f\"Loaded lexicon: {path} ({len(df):,} entries)\")\n",
    "        return dict(zip(df[key_col], df[val_col]))\n",
    "    print(f\"(Optional) Not found: {path}\")\n",
    "    return {}\n",
    "\n",
    "EN_SLANG  = load_lexicon_csv(\"english_slang.csv\", \"slang\", \"normalized\")\n",
    "ID_SLANG  = load_lexicon_csv(\"indonesian_slang.csv\", \"slang\", \"normalized\")\n",
    "EMOJI_MAP = load_lexicon_csv(\"emoji_map.csv\", \"emoji\", \"normalized\")\n",
    "\n",
    "def sanitize_token(s: str) -> str:\n",
    "    return re.sub(r\"[^\\w']\", \"\", s.lower())\n",
    "\n",
    "def sanitize_map(m: dict) -> dict:\n",
    "    out = {}\n",
    "    for k, v in m.items():\n",
    "        sk = sanitize_token(k)\n",
    "        sv = sanitize_token(v)\n",
    "        if sk and sv:\n",
    "            out[sk] = sv\n",
    "    return out\n",
    "\n",
    "SLANG_MAP = {}\n",
    "SLANG_MAP.update(sanitize_map(EN_SLANG))\n",
    "SLANG_MAP.update(sanitize_map(ID_SLANG))\n",
    "if not SLANG_MAP:\n",
    "    SLANG_MAP.update({\n",
    "        \"idk\":\"i do not know\",\"imo\":\"in my opinion\",\"imho\":\"in my humble opinion\",\n",
    "        \"btw\":\"by the way\",\"tbh\":\"to be honest\",\"omg\":\"oh my god\",\"wtf\":\"what the fuck\",\n",
    "        \"ikr\":\"i know right\",\"thx\":\"thanks\",\"pls\":\"please\",\"u\":\"you\",\"ur\":\"your\",\n",
    "        \"dont\":\"do not\",\"cant\":\"cannot\",\"wont\":\"will not\",\"ive\":\"i have\",\n",
    "        \"isnt\":\"is not\",\"wasnt\":\"was not\",\"arent\":\"are not\",\"w\":\"win\",\"l\":\"loss\"\n",
    "    })\n",
    "\n",
    "def build_text_processor():\n",
    "    return TextPreProcessor(\n",
    "        normalize=['url','email','percent','money','phone','time','date'],\n",
    "        annotate={'hashtag','allcaps','elongated','repeated'},\n",
    "        fix_html=True,\n",
    "        segmenter='twitter',\n",
    "        corrector='twitter',\n",
    "        unpack_hashtags=True,\n",
    "        unpack_contractions=True,\n",
    "        tokenizer=SocialTokenizer(lowercase=False).tokenize,\n",
    "        dicts=[]\n",
    "    )\n",
    "\n",
    "text_processor = build_text_processor()\n",
    "print(\"✅ text_processor ready | slang entries:\", len(SLANG_MAP))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf59ce2",
   "metadata": {},
   "source": [
    "## Helper functions: cleaning → lower → social/slang → token → stopword → stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b27fb38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helpers ready\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 986 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "URL_RE       = re.compile(r\"(https?://\\S+|www\\.)\\S+\", re.IGNORECASE)\n",
    "MD_LINK_RE   = re.compile(r\"\\[.*?\\]\\(.*?\\)\")\n",
    "HTML_TAG_RE  = re.compile(r\"<.*?>\")\n",
    "MENTION_RE   = re.compile(r\"@\\w+\")\n",
    "NONPRINT_RE  = re.compile(r\"[\\x00-\\x1f\\x7f]\")\n",
    "\n",
    "def is_irrelevant(text: str) -> bool:\n",
    "    if not isinstance(text, str): return True\n",
    "    t = text.strip()\n",
    "    if not t: return True\n",
    "    if t.lower() in (\"[deleted]\",\"[removed]\"): return True\n",
    "    t2 = URL_RE.sub(\" \", t)\n",
    "    t2 = MD_LINK_RE.sub(\" \", t2)\n",
    "    t2 = HTML_TAG_RE.sub(\" \", t2)\n",
    "    words = [w for w in re.split(r\"\\s+\", t2.strip()) if w]\n",
    "    if len(words) <= 2: return True\n",
    "    if re.fullmatch(r\"[^A-Za-z]+\", (t2.strip() or \"\")): return True\n",
    "    return False\n",
    "\n",
    "def cleaning_step(text: str) -> str:\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    x = fix_text(text)\n",
    "    x = URL_RE.sub(\" \", x)\n",
    "    x = MD_LINK_RE.sub(\" \", x)\n",
    "    x = HTML_TAG_RE.sub(\" \", x)\n",
    "    x = MENTION_RE.sub(\" \", x)\n",
    "    x = NONPRINT_RE.sub(\" \", x)\n",
    "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "    return x\n",
    "\n",
    "def case_folding_step(text: str) -> str:\n",
    "    return text.lower().strip()\n",
    "\n",
    "def social_normalize_step(text: str) -> str:\n",
    "    toks = text_processor.pre_process_doc(text)\n",
    "    sent = \" \".join(toks)\n",
    "    sent = demojize(sent)\n",
    "    if EMOJI_MAP:\n",
    "        for emo, rep in EMOJI_MAP.items():\n",
    "            sent = sent.replace(emo, rep)\n",
    "    return re.sub(r\"\\s+\", \" \", sent).strip()\n",
    "\n",
    "def slang_replace_step(text: str) -> str:\n",
    "    tokens = re.split(r\"\\s+\", text)\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        base = sanitize_token(t)\n",
    "        out.append(SLANG_MAP.get(base, t))\n",
    "    return \" \".join(out)\n",
    "\n",
    "def tokenize_step(text: str) -> list:\n",
    "    toks = TOK.tokenize(text)\n",
    "    return [t for t in toks if t.isalpha()]\n",
    "\n",
    "def stopword_removal_step(tokens: list) -> list:\n",
    "    return [t for t in tokens if t not in STOPWORDS]\n",
    "\n",
    "def stemming_step(tokens: list) -> list:\n",
    "    return [STEMMER.stem(t) for t in tokens]\n",
    "\n",
    "def to_final_text(tokens: list) -> str:\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def month_str(dt_series: pd.Series) -> pd.Series:\n",
    "    return dt_series.dt.to_period(\"M\").astype(str)\n",
    "\n",
    "print(\"✅ Helpers ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9cb001",
   "metadata": {},
   "source": [
    "## Preview kecil: 5 baris pertama yang relevan (2024 window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f66b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### PREVIEW 2024 WINDOW ###\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doesn't the PM have parliamentary immunity whi...</td>\n",
       "      <td>doesn't the PM have parliamentary immunity whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have read the history of the Levant. And the...</td>\n",
       "      <td>I have read the history of the Levant. And the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAS being the operative word and he made no se...</td>\n",
       "      <td>WAS being the operative word and he made no se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obviously there's multiple reasons why we don'...</td>\n",
       "      <td>Obviously there's multiple reasons why we don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somehow I think Lockmart is fine with this. It...</td>\n",
       "      <td>Somehow I think Lockmart is fine with this. It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              before  \\\n",
       "0  doesn't the PM have parliamentary immunity whi...   \n",
       "1  I have read the history of the Levant. And the...   \n",
       "2  WAS being the operative word and he made no se...   \n",
       "3  Obviously there's multiple reasons why we don'...   \n",
       "4  Somehow I think Lockmart is fine with this. It...   \n",
       "\n",
       "                                               after  \n",
       "0  doesn't the PM have parliamentary immunity whi...  \n",
       "1  I have read the history of the Levant. And the...  \n",
       "2  WAS being the operative word and he made no se...  \n",
       "3  Obviously there's multiple reasons why we don'...  \n",
       "4  Somehow I think Lockmart is fine with this. It...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doesn't the PM have parliamentary immunity whi...</td>\n",
       "      <td>doesn't the pm have parliamentary immunity whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have read the history of the Levant. And the...</td>\n",
       "      <td>i have read the history of the levant. and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAS being the operative word and he made no se...</td>\n",
       "      <td>was being the operative word and he made no se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obviously there's multiple reasons why we don'...</td>\n",
       "      <td>obviously there's multiple reasons why we don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somehow I think Lockmart is fine with this. It...</td>\n",
       "      <td>somehow i think lockmart is fine with this. it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              before  \\\n",
       "0  doesn't the PM have parliamentary immunity whi...   \n",
       "1  I have read the history of the Levant. And the...   \n",
       "2  WAS being the operative word and he made no se...   \n",
       "3  Obviously there's multiple reasons why we don'...   \n",
       "4  Somehow I think Lockmart is fine with this. It...   \n",
       "\n",
       "                                               after  \n",
       "0  doesn't the pm have parliamentary immunity whi...  \n",
       "1  i have read the history of the levant. and the...  \n",
       "2  was being the operative word and he made no se...  \n",
       "3  obviously there's multiple reasons why we don'...  \n",
       "4  somehow i think lockmart is fine with this. it...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doesn't the pm have parliamentary immunity whi...</td>\n",
       "      <td>does not the pm have parliamentary immunity wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have read the history of the levant. and the...</td>\n",
       "      <td>i have read the history of the levant . and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was being the operative word and he made no se...</td>\n",
       "      <td>was being the operative word and he made no se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obviously there's multiple reasons why we don'...</td>\n",
       "      <td>obviously there ' s multiple reasons why we do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somehow i think lockmart is fine with this. it...</td>\n",
       "      <td>somehow i think lockmart is fine with this . i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              before  \\\n",
       "0  doesn't the pm have parliamentary immunity whi...   \n",
       "1  i have read the history of the levant. and the...   \n",
       "2  was being the operative word and he made no se...   \n",
       "3  obviously there's multiple reasons why we don'...   \n",
       "4  somehow i think lockmart is fine with this. it...   \n",
       "\n",
       "                                               after  \n",
       "0  does not the pm have parliamentary immunity wh...  \n",
       "1  i have read the history of the levant . and th...  \n",
       "2  was being the operative word and he made no se...  \n",
       "3  obviously there ' s multiple reasons why we do...  \n",
       "4  somehow i think lockmart is fine with this . i...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does not the pm have parliamentary immunity wh...</td>\n",
       "      <td>[does, not, the, pm, have, parliamentary, immu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have read the history of the levant . and th...</td>\n",
       "      <td>[i, have, read, the, history, of, the, levant,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was being the operative word and he made no se...</td>\n",
       "      <td>[was, being, the, operative, word, and, he, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obviously there ' s multiple reasons why we do...</td>\n",
       "      <td>[obviously, there, s, multiple, reasons, why, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somehow i think lockmart is fine with this . i...</td>\n",
       "      <td>[somehow, i, think, lockmart, is, fine, with, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              before  \\\n",
       "0  does not the pm have parliamentary immunity wh...   \n",
       "1  i have read the history of the levant . and th...   \n",
       "2  was being the operative word and he made no se...   \n",
       "3  obviously there ' s multiple reasons why we do...   \n",
       "4  somehow i think lockmart is fine with this . i...   \n",
       "\n",
       "                                               after  \n",
       "0  [does, not, the, pm, have, parliamentary, immu...  \n",
       "1  [i, have, read, the, history, of, the, levant,...  \n",
       "2  [was, being, the, operative, word, and, he, ma...  \n",
       "3  [obviously, there, s, multiple, reasons, why, ...  \n",
       "4  [somehow, i, think, lockmart, is, fine, with, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[does, not, the, pm, have, parliamentary, immu...</td>\n",
       "      <td>[pm, parliamentary, immunity, office]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i, have, read, the, history, of, the, levant,...</td>\n",
       "      <td>[read, history, levant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[was, being, the, operative, word, and, he, ma...</td>\n",
       "      <td>[operative, word, made, secret, saved, civilia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[obviously, there, s, multiple, reasons, why, ...</td>\n",
       "      <td>[obviously, multiple, reasons, bomb, nk, respe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[somehow, i, think, lockmart, is, fine, with, ...</td>\n",
       "      <td>[somehow, think, lockmart, fine, make, new, pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              before  \\\n",
       "0  [does, not, the, pm, have, parliamentary, immu...   \n",
       "1  [i, have, read, the, history, of, the, levant,...   \n",
       "2  [was, being, the, operative, word, and, he, ma...   \n",
       "3  [obviously, there, s, multiple, reasons, why, ...   \n",
       "4  [somehow, i, think, lockmart, is, fine, with, ...   \n",
       "\n",
       "                                               after  \n",
       "0              [pm, parliamentary, immunity, office]  \n",
       "1                            [read, history, levant]  \n",
       "2  [operative, word, made, secret, saved, civilia...  \n",
       "3  [obviously, multiple, reasons, bomb, nk, respe...  \n",
       "4  [somehow, think, lockmart, fine, make, new, pl...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pm, parliamentary, immunity, office]</td>\n",
       "      <td>[pm, parliamentari, immun, offic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[read, history, levant]</td>\n",
       "      <td>[read, histori, levant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[operative, word, made, secret, saved, civilia...</td>\n",
       "      <td>[oper, word, made, secret, save, civilian, live]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[obviously, multiple, reasons, bomb, nk, respe...</td>\n",
       "      <td>[obvious, multipl, reason, bomb, nk, respect, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[somehow, think, lockmart, fine, make, new, pl...</td>\n",
       "      <td>[somehow, think, lockmart, fine, make, new, pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              before  \\\n",
       "0              [pm, parliamentary, immunity, office]   \n",
       "1                            [read, history, levant]   \n",
       "2  [operative, word, made, secret, saved, civilia...   \n",
       "3  [obviously, multiple, reasons, bomb, nk, respe...   \n",
       "4  [somehow, think, lockmart, fine, make, new, pl...   \n",
       "\n",
       "                                               after  \n",
       "0                  [pm, parliamentari, immun, offic]  \n",
       "1                            [read, histori, levant]  \n",
       "2   [oper, word, made, secret, save, civilian, live]  \n",
       "3  [obvious, multipl, reason, bomb, nk, respect, ...  \n",
       "4  [somehow, think, lockmart, fine, make, new, pl...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slang_replaced</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does not the pm have parliamentary immunity wh...</td>\n",
       "      <td>pm parliamentari immun offic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have read the history of the levant . and th...</td>\n",
       "      <td>read histori levant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was being the operative word and he made no se...</td>\n",
       "      <td>oper word made secret save civilian live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>obviously there ' s multiple reasons why we do...</td>\n",
       "      <td>obvious multipl reason bomb nk respect armisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>somehow i think lockmart is fine with this . i...</td>\n",
       "      <td>somehow think lockmart fine make new plane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      slang_replaced  \\\n",
       "0  does not the pm have parliamentary immunity wh...   \n",
       "1  i have read the history of the levant . and th...   \n",
       "2  was being the operative word and he made no se...   \n",
       "3  obviously there ' s multiple reasons why we do...   \n",
       "4  somehow i think lockmart is fine with this . i...   \n",
       "\n",
       "                                          final_text  \n",
       "0                       pm parliamentari immun offic  \n",
       "1                                read histori levant  \n",
       "2           oper word made secret save civilian live  \n",
       "3  obvious multipl reason bomb nk respect armisti...  \n",
       "4         somehow think lockmart fine make new plane  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.8 s\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def preview_steps(file_path, n=5):\n",
    "    prev = None\n",
    "    for chunk in pd.read_csv(file_path, chunksize=200_000, low_memory=False):\n",
    "        if \"self_text\" not in chunk.columns:\n",
    "            raise ValueError(\"Kolom 'self_text' tidak ditemukan.\")\n",
    "        sub = chunk[~chunk[\"self_text\"].apply(is_irrelevant)].copy()\n",
    "        if len(sub) >= n:\n",
    "            prev = sub.head(n).copy()\n",
    "            break\n",
    "    if prev is None:\n",
    "        print(\"Tidak ada baris relevan untuk preview.\")\n",
    "        return\n",
    "\n",
    "    tmp = prev.copy()\n",
    "    tmp[\"after\"] = tmp[\"self_text\"].apply(cleaning_step)\n",
    "    display(tmp.loc[:, [\"self_text\",\"after\"]].rename(columns={\"self_text\":\"before\"}))\n",
    "\n",
    "    tmp = tmp.rename(columns={\"after\":\"cleaned\"})\n",
    "    tmp[\"after\"] = tmp[\"cleaned\"].apply(case_folding_step)\n",
    "    display(tmp.loc[:, [\"cleaned\",\"after\"]].rename(columns={\"cleaned\":\"before\"}))\n",
    "\n",
    "    tmp = tmp.rename(columns={\"after\":\"lowered\"})\n",
    "    tmp[\"soc\"] = tmp[\"lowered\"].apply(social_normalize_step)\n",
    "    tmp[\"after\"] = tmp[\"soc\"].apply(slang_replace_step)\n",
    "    display(tmp.loc[:, [\"lowered\",\"after\"]].rename(columns={\"lowered\":\"before\"}))\n",
    "\n",
    "    tmp = tmp.rename(columns={\"after\":\"slang_replaced\"})\n",
    "    tmp[\"after\"] = tmp[\"slang_replaced\"].apply(tokenize_step)\n",
    "    display(tmp.loc[:, [\"slang_replaced\",\"after\"]].rename(columns={\"slang_replaced\":\"before\"}))\n",
    "\n",
    "    tmp = tmp.rename(columns={\"after\":\"tokens\"})\n",
    "    tmp[\"after\"] = tmp[\"tokens\"].apply(stopword_removal_step)\n",
    "    display(tmp.loc[:, [\"tokens\",\"after\"]].rename(columns={\"tokens\":\"before\"}))\n",
    "\n",
    "    tmp = tmp.rename(columns={\"after\":\"no_stop\"})\n",
    "    tmp[\"after\"] = tmp[\"no_stop\"].apply(stemming_step)\n",
    "    display(tmp.loc[:, [\"no_stop\",\"after\"]].rename(columns={\"no_stop\":\"before\"}))\n",
    "\n",
    "    tmp = tmp.rename(columns={\"after\":\"stemmed\"})\n",
    "    tmp[\"final_text\"] = tmp[\"stemmed\"].apply(to_final_text)\n",
    "    display(tmp.loc[:, [\"slang_replaced\",\"final_text\"]])\n",
    "\n",
    "print(\"### PREVIEW 2024 WINDOW ###\")\n",
    "if os.path.exists(IN_2024):\n",
    "    preview_steps(IN_2024, PREVIEW_ROWS)\n",
    "else:\n",
    "    print(\"File tidak ditemukan:\", IN_2024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7e11d",
   "metadata": {},
   "source": [
    "## Fungsi utama: preprocess streaming per file (window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "091eb19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 9.06 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def preprocess_file(input_path, output_path, chunksize=500_000):\n",
    "    if os.path.exists(output_path):\n",
    "        os.remove(output_path)\n",
    "\n",
    "    wrote_header = False\n",
    "    total_in = total_out = 0\n",
    "\n",
    "    for chunk in pd.read_csv(input_path, chunksize=chunksize, low_memory=False, parse_dates=[\"created_time\"]):\n",
    "        total_in += len(chunk)\n",
    "        if \"self_text\" not in chunk.columns:\n",
    "            raise ValueError(\"Kolom 'self_text' tidak ditemukan.\")\n",
    "\n",
    "        # buang baris tak relevan\n",
    "        chunk = chunk[~chunk[\"self_text\"].apply(is_irrelevant)].copy()\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # pipeline teks\n",
    "        chunk[\"cleaned\"] = chunk[\"self_text\"].apply(cleaning_step)\n",
    "        chunk[\"lowered\"] = chunk[\"cleaned\"].apply(case_folding_step)\n",
    "        chunk[\"soc\"] = chunk[\"lowered\"].apply(social_normalize_step)\n",
    "        chunk[\"slang_replaced\"] = chunk[\"soc\"].apply(slang_replace_step)\n",
    "        chunk[\"tokens\"] = chunk[\"slang_replaced\"].apply(tokenize_step)\n",
    "        chunk[\"no_stop\"] = chunk[\"tokens\"].apply(stopword_removal_step)\n",
    "        chunk[\"stemmed\"] = chunk[\"no_stop\"].apply(stemming_step)\n",
    "        chunk[\"final_text\"] = chunk[\"stemmed\"].apply(to_final_text)\n",
    "\n",
    "        # drop kosong & jaga tanggal\n",
    "        chunk = chunk[chunk[\"final_text\"].str.strip() != \"\"].copy()\n",
    "        chunk = chunk[chunk[\"created_time\"].notna()].copy()\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # kolom bulan\n",
    "        chunk[\"month\"] = month_str(chunk[\"created_time\"])\n",
    "\n",
    "        # pastikan kolom simpan tersedia\n",
    "        for c in KEEP_COLS:\n",
    "            if c not in chunk.columns:\n",
    "                chunk[c] = None\n",
    "\n",
    "        out = chunk[KEEP_COLS + [\"final_text\",\"month\"]].copy()\n",
    "        out.to_csv(output_path, mode=\"a\", index=False, header=not wrote_header)\n",
    "        wrote_header = True\n",
    "        total_out += len(out)\n",
    "\n",
    "        print(f\"Chunk → wrote {len(out):,} (total {total_out:,})\")\n",
    "\n",
    "    print(f\"\\n✅ DONE preprocess: {input_path}\")\n",
    "    print(f\"  Total input: {total_in:,}\")\n",
    "    print(f\"  Total kept : {total_out:,}\")\n",
    "    print(f\"  Output     : {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa10c7",
   "metadata": {},
   "source": [
    "## Jalankan preprocess untuk 2024 window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e7db47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk → wrote 477,577 (total 477,577)\n",
      "Chunk → wrote 81,267 (total 558,844)\n",
      "\n",
      "✅ DONE preprocess: reddit_opinion_PSE_ISR_2024_window.csv\n",
      "  Total input: 585,053\n",
      "  Total kept : 558,844\n",
      "  Output     : reddit_opinion_PSE_ISR_2024_window_clean.csv\n",
      "CPU times: total: 12min 17s\n",
      "Wall time: 12min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.exists(IN_2024):\n",
    "    preprocess_file(IN_2024, OUT_2024, CHUNKSIZE)\n",
    "else:\n",
    "    print(\"File 2024 window tidak ditemukan:\", IN_2024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5881717",
   "metadata": {},
   "source": [
    "## Jalankan preprocess untuk 2025 window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93135f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk → wrote 294,411 (total 294,411)\n",
      "\n",
      "✅ DONE preprocess: reddit_opinion_PSE_ISR_2025_window.csv\n",
      "  Total input: 307,018\n",
      "  Total kept : 294,411\n",
      "  Output     : reddit_opinion_PSE_ISR_2025_window_clean.csv\n",
      "CPU times: total: 7min 5s\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.exists(IN_2025):\n",
    "    preprocess_file(IN_2025, OUT_2025, CHUNKSIZE)\n",
    "else:\n",
    "    print(\"File 2025 window tidak ditemukan:\", IN_2025)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e28fa54",
   "metadata": {},
   "source": [
    "## Verifikasi cepat: ukuran & 5 baris teratas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b32dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit_opinion_PSE_ISR_2024_window_clean.csv: 237.57 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>self_text</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>final_text</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m1g0pi5</td>\n",
       "      <td>2024-12-10 23:59:55</td>\n",
       "      <td>doesn't the PM have parliamentary immunity whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>pm parliamentari immun offic</td>\n",
       "      <td>2024-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m1g0okb</td>\n",
       "      <td>2024-12-10 23:59:45</td>\n",
       "      <td>I have read the history of the Levant. And the...</td>\n",
       "      <td>-25</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>read histori levant</td>\n",
       "      <td>2024-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m1g0ok1</td>\n",
       "      <td>2024-12-10 23:59:45</td>\n",
       "      <td>WAS being the operative word and he made no se...</td>\n",
       "      <td>1</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>oper word made secret save civilian live</td>\n",
       "      <td>2024-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m1g0m2l</td>\n",
       "      <td>2024-12-10 23:59:21</td>\n",
       "      <td>Obviously there's multiple reasons why we don'...</td>\n",
       "      <td>-8</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>obvious multipl reason bomb nk respect armisti...</td>\n",
       "      <td>2024-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m1g0l5s</td>\n",
       "      <td>2024-12-10 23:59:12</td>\n",
       "      <td>Somehow I think Lockmart is fine with this. It...</td>\n",
       "      <td>7</td>\n",
       "      <td>NonCredibleDefense</td>\n",
       "      <td>somehow think lockmart fine make new plane</td>\n",
       "      <td>2024-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id         created_time  \\\n",
       "0    m1g0pi5  2024-12-10 23:59:55   \n",
       "1    m1g0okb  2024-12-10 23:59:45   \n",
       "2    m1g0ok1  2024-12-10 23:59:45   \n",
       "3    m1g0m2l  2024-12-10 23:59:21   \n",
       "4    m1g0l5s  2024-12-10 23:59:12   \n",
       "\n",
       "                                           self_text  score  \\\n",
       "0  doesn't the PM have parliamentary immunity whi...      1   \n",
       "1  I have read the history of the Levant. And the...    -25   \n",
       "2  WAS being the operative word and he made no se...      1   \n",
       "3  Obviously there's multiple reasons why we don'...     -8   \n",
       "4  Somehow I think Lockmart is fine with this. It...      7   \n",
       "\n",
       "            subreddit                                         final_text  \\\n",
       "0           worldnews                       pm parliamentari immun offic   \n",
       "1           worldnews                                read histori levant   \n",
       "2     IsraelPalestine           oper word made secret save civilian live   \n",
       "3       CombatFootage  obvious multipl reason bomb nk respect armisti...   \n",
       "4  NonCredibleDefense         somehow think lockmart fine make new plane   \n",
       "\n",
       "     month  \n",
       "0  2024-12  \n",
       "1  2024-12  \n",
       "2  2024-12  \n",
       "3  2024-12  \n",
       "4  2024-12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit_opinion_PSE_ISR_2025_window_clean.csv: 136.80 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>created_time</th>\n",
       "      <th>self_text</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>final_text</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ndjojnm</td>\n",
       "      <td>2025-09-10 23:59:37</td>\n",
       "      <td>That’s all old stuff. It has been already disc...</td>\n",
       "      <td>3</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>old stuff alreadi discuss ad nauseam two year ...</td>\n",
       "      <td>2025-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ndjohss</td>\n",
       "      <td>2025-09-10 23:59:19</td>\n",
       "      <td>May be stop sending Iranian drones. ? \\nThere ...</td>\n",
       "      <td>310</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>may stop send iranian drone reason israel atta...</td>\n",
       "      <td>2025-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ndjo93p</td>\n",
       "      <td>2025-09-10 23:57:58</td>\n",
       "      <td>Google was founded by Page and Brin. Larry Pag...</td>\n",
       "      <td>1</td>\n",
       "      <td>IsraelPalestine</td>\n",
       "      <td>googl found page brin larri page michigan serg...</td>\n",
       "      <td>2025-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ndjo760</td>\n",
       "      <td>2025-09-10 23:57:39</td>\n",
       "      <td>The difference is that it appears the Qatari k...</td>\n",
       "      <td>24</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>differ appear qatari knew allow proceed canadi...</td>\n",
       "      <td>2025-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ndjo435</td>\n",
       "      <td>2025-09-10 23:57:11</td>\n",
       "      <td>Take a look at the video on instagram.  The da...</td>\n",
       "      <td>12</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>take look video instagram damag small video cl...</td>\n",
       "      <td>2025-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id         created_time  \\\n",
       "0    ndjojnm  2025-09-10 23:59:37   \n",
       "1    ndjohss  2025-09-10 23:59:19   \n",
       "2    ndjo93p  2025-09-10 23:57:58   \n",
       "3    ndjo760  2025-09-10 23:57:39   \n",
       "4    ndjo435  2025-09-10 23:57:11   \n",
       "\n",
       "                                           self_text  score        subreddit  \\\n",
       "0  That’s all old stuff. It has been already disc...      3  IsraelPalestine   \n",
       "1  May be stop sending Iranian drones. ? \\nThere ...    310        worldnews   \n",
       "2  Google was founded by Page and Brin. Larry Pag...      1  IsraelPalestine   \n",
       "3  The difference is that it appears the Qatari k...     24        worldnews   \n",
       "4  Take a look at the video on instagram.  The da...     12        worldnews   \n",
       "\n",
       "                                          final_text    month  \n",
       "0  old stuff alreadi discuss ad nauseam two year ...  2025-09  \n",
       "1  may stop send iranian drone reason israel atta...  2025-09  \n",
       "2  googl found page brin larri page michigan serg...  2025-09  \n",
       "3  differ appear qatari knew allow proceed canadi...  2025-09  \n",
       "4  take look video instagram damag small video cl...  2025-09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 72.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for out in [OUT_2024, OUT_2025]:\n",
    "    if os.path.exists(out):\n",
    "        sz = os.path.getsize(out)/(1024**2)\n",
    "        print(f\"{out}: {sz:.2f} MB\")\n",
    "        display(pd.read_csv(out, nrows=5))\n",
    "    else:\n",
    "        print(\"Tidak ditemukan:\", out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
